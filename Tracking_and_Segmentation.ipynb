{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tracking_and_Segmentation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NTUWYZxc2rGD","colab_type":"text"},"source":["# Connect to google drive files"]},{"cell_type":"code","metadata":{"id":"pMoXZrnW4MSW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"9ce5b509-00cd-484a-9f7c-1b0326419625","executionInfo":{"status":"ok","timestamp":1572025544221,"user_tz":360,"elapsed":3566,"user":{"displayName":"Erick Alejandro Mu単oz Alvarado","photoUrl":"","userId":"06421202750453488421"}}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# Mount the drive folder. This will prompt for authorization.\n","drive.mount('/content/drive/', force_remount=True)\n","\n","%cd drive/My\\ Drive/PARMA/OpticalFlow/GitRepo/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/My Drive/PARMA/OpticalFlow/GitRepo\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GWkcPSDc4WGg","colab_type":"text"},"source":["# Artificial dataset generation\n","\n","Call to animator.py to generate the desired dataset.\n","Animator.py call takes some parametters some of them are:\n","\n","\n","*   **-s or --step:** The script generates a maximm of 5k samples, the step reduces this number so that the max samples will be max//step\n","*   **-e or --eev:** Defines the magnitude of the noise added to the movement of the particles, it's measured in pixels\n","*   **-t or --trajectory:** Defines the trajectory of the circles generated, it can be sen, df or shuffle if you want a bit of both worlds\n","*   **-d or --dir:** Sets de directory to store the generated dataset **IT MUST HAVE A FOLDER CALLED WORK INSIDE**\n","*   **-n or --num:** The number of circles you want to generate \n","\n","In the end the call will look like this:\n"]},{"cell_type":"code","metadata":{"id":"MgwrWOeT-lYY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":503},"outputId":"6d3ab9bd-c1e7-4ee7-8e78-313beeab18f0","executionInfo":{"status":"ok","timestamp":1572025451496,"user_tz":360,"elapsed":1179406,"user":{"displayName":"Erick Alejandro Mu単oz Alvarado","photoUrl":"","userId":"06421202750453488421"}}},"source":["!python3 DatasetGenerator/animator.py -s 3 -e 2 -t shuffle -d /content/drive/My\\ Drive/PARMA/OpticalFlow/GitRepo/Dataset/test/ -n 5"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using a step of 3 will result in 1666 frames\n","Using a standar deviation of: 2\n","Drawing a shuffle trajectory\n","Using /content/drive/My Drive/PARMA/OpticalFlow/GitRepo/Dataset/test/ as save directory\n","Looking for bg in /content/drive/My Drive/PARMA/OpticalFlow/GitRepo/Dataset/OriginalVideo/\n","------------------------------------------------------- Adding circle #0 -------------------------------------------------------\n","49\n","47.818051754967556\n","Generating df animation: 100% 1666/1666 [03:45<00:00,  6.79it/s]\n","Mixing background and animation...: 100% 1666/1666 [05:36<00:00,  4.96it/s]\n","------------------------------------------------------- Adding circle #1 -------------------------------------------------------\n","11\n","9.459504317096396\n","Generating sen animation: 100% 1666/1666 [03:48<00:00,  6.12it/s]\n","Mixing background and animation...: 100% 1666/1666 [02:14<00:00, 10.13it/s]\n","------------------------------------------------------- Adding circle #2 -------------------------------------------------------\n","24\n","22.169449539786942\n","Generating df animation:  99% 1648/1666 [03:44<00:02,  6.75it/s]Traceback (most recent call last):\n","  File \"DatasetGenerator/animator.py\", line 159, in <module>\n","    original_dir)\n","  File \"DatasetGenerator/animator.py\", line 47, in single_animation\n","    circle_animation.animate(colors_val.pop(0))\n","  File \"/content/drive/My Drive/PARMA/OpticalFlow/GitRepo/DatasetGenerator/CircleAnimation.py\", line 80, in animate\n","  File \"/usr/local/lib/python3.6/dist-packages/scipy/signal/signaltools.py\", line 1066, in convolve2d\n","    out = sigtools._convolve2d(in1, in2, 1, val, bval, fillvalue)\n","KeyboardInterrupt\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m7F-akdr1gmC"},"source":["This wil generate the dataset we wanted in the targeted directory, know we can start procesing them\n","\n","# Training the Elman network for tracking\n","\n","The Elman network will help us track each circle individually, so we feed it with the trajectories of the circles to train\n","\n","Thescript take some arguments to work:\n","\n","* **-d or --ds:** Directory to look for the dataset.\n","* **-s or --st:** Directory to store the weights."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KDtgc5k21atD","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"4f2066f0-8621-4977-8eea-c82b011e16b3","executionInfo":{"status":"ok","timestamp":1572025555560,"user_tz":360,"elapsed":9725,"user":{"displayName":"Erick Alejandro Mu単oz Alvarado","photoUrl":"","userId":"06421202750453488421"}}},"source":["!python3 ObjectTracking/ElmanNet.py -d /content/drive/My Drive/PARMA/OpticalFlow/GitRepo/Dataset/test/ -s /content/drive/My Drive/PARMA/OpticalFlow/GitRepo/ObjectTracking/WeigthsResults/ -a training"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"ObjectTracking/ElmanNet.py\", line 470, in <module>\n","    opts, args = getopt.getopt(sys.argv[1:],\"hd:s:\",[\"ds=\",\"st=\"])\n","NameError: name 'sys' is not defined\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lH0meWxOo80O","colab_type":"text"},"source":["# Training U-Net for segmentation\n","\n","\n","The U-Net will be in charge of creating of segmentation of the circles in the image. So train it with a secuence of images filled\n","\n","* **-t or --training:** Directory to look for the training dataset\n","* **-v or --validation:** Directory to look for the test dataset\n","* **-g or --gtt:** Directory to look for the training groud truth\n","* **-j or --gtv:** Directory to look for the test groud truth\n","* **-s or --store:** Directory to store the weights\n","* **-a or --action:** Training or prediction"]},{"cell_type":"code","metadata":{"id":"kjR8-sHNhhXS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"b01bcc8b-1fc6-4d3a-a2ac-d940753e45db","executionInfo":{"status":"ok","timestamp":1572024119731,"user_tz":360,"elapsed":747596,"user":{"displayName":"Erick Alejandro Mu単oz Alvarado","photoUrl":"","userId":"06421202750453488421"}}},"source":["#!unet3_reduced.py -t <training dataset directory> -v <validation dataset directory> -g <train gt dataset directory> -j <val gt dataset directory> -s <store directory> -a <train of predict>"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n","/bin/bash: -c: line 0: `unet3_reduced.py -t <training dataset directory> -v <validation dataset directory> -g <train gt dataset directory> -j <val gt dataset directory> -s <store directory> -a <train of predict>'\n"],"name":"stdout"}]}]}